The most effective way to test the system is to attack it. To do so, some of the most used kernel rootkits techniques were explored to better understand how attacks are typically implemented. In particular, great material for attack techniques was found in two GitHub repositories which are meant to show rootkits methods for learning purposes. These two rootkits are Diamorphine \cite{diamorph} and Reptile \cite{reptile} (which comes with particularly interesting slides \cite{rootkit-techniques} from the authors). 
\par 
To actually attack the system, a Loadable Kernel Module was implemented, as it is the de facto standard way to implement rootkits. The Loadable Kernel Module has a parameter that can be used to specify the attack type it has to perform.  The following section goes through a possible attack scenario, describing in detail the steps performed by an attacker and how the proposed system can detect or even prevent them from being performed successfully.

\section{An attack scenario}
As discussed in the threat modeling section, the attacker modeled in this work is an external one. Typically, when attacking a system, the attacker tries to gain access to a shell to execute commands inside the victim machine. This is called Remote Code Execution, or RCE for short. Most of the time, it is achieved by exploiting vulnerabilities in the services offered by the virtual machine, e.g a web server, and forcing it to execute a reverse shell, where the victim machine connects to the attacker one, waiting for incoming commands. Usually, a web server runs as a particular user inside the system and the attacker has to upgrade its credentials running commands as this user. The proposed system may detect this situation by checking two different aspects: 
\begin{itemize}
    \item Usually, shell processes do not run with the credentials of the user reserved for the web server. For this reason, it may be possible to use this as a sign of intrusion. 
    \item In addition, also network connections can be used. Since the attacker forced the web server to execute a reverse shell, an unexpected outbound connection can be noticed and treated as a sign of intrusion.
\end{itemize}
The proposed system can easily implement these kinds of checks. This could be done by stating a set of rules and checking data that was retrieved from the virtual machine, like the process list described earlier, against them. For the moment, the system limits itself to simply detect this kind of situations, but it could also try to block the attack by killing the process, for instance. However, this is not the major concern of this work and it was not implemented, even if it could be implemented in the future. 
\par
The attacker's next step is to upgrade its credential. Typically, the aim is to gain \emph{root} access, and this can be achieved step by step by upgrading the credentials to other users of the system first. There is a multitude of ways to accomplish this, but in general attackers have three different ways of doing that: 
\begin{itemize}
    \item Attacking root processes and trying to let them execute code to the benefit of the attacker
    \item Attacking executable files owned by root with the \texttt{SUID} bit enabled and again trying to let them execute code to the benefit of the attacker
    \item Attacking the underlying kernel
\end{itemize}
The activities carried out by the attacker inside the system are still monitored through the use of the guest agent, and there are multiple other ways to detect signs of intrusion. Supposing that the attacker is gaining root access anyway in some way, she will then try to obtain persistence of the attack, usually by inserting a Loadable Kernel Module, i.e a rootkit, and running code at Ring 0. There is a multitude of actions the attacker can take to try to subvert the proposed system or to easily regain root access whenever it is needed. Many of these attack steps where implemented to test the robustness of the system. 
\par
One of the first objectives could be to prevent the monitoring code to execute. This can be done in at least two ways: 
\begin{itemize}
    \item The first one could be the attacking of the function pointer pointing to the handler function that encapsulates the monitoring code. As the the careful reader may remember, that pointer resides in the \texttt{irqaction} data structure. The attacker can try to make it point to an empty function, thus completely disabling the overall system. 
    \item Another kind of attack could be modifying the entry of the IDT that leads to the execution of the FX interrupt handler to not call that function anymore. This can be done by modifying that entry in the current IDT or creating a fake IDT and making IDTR point it, or changing the page tables to point to the new fake one.
\end{itemize}
These kind of attacks were proved unsuccessful against the proposed system. This is mainly due to the memory write protection hypercall and the Save \& Reload approach. The IDT is successfully marked as read only, important data structures' state are saved and reloaded just before the injection of the interrupt, modifications of IDTR are not possible thanks to the pinning of that register. Furthermore, also all the involved page tables entries are reloaded before executing the monitoring code. In conclusion, all techniques previously discussed were very useful to prevent the attacker tamper with the system.  
\par
In any case, the attacker could still try to not subvert the system but to install a rootkit to regain root access easily. To test whether the proposed system also increased the security level of the running kernel, some of most used rootkit techniques were used, inspired by Diamorphine and Reptile. One of the most used way to attack the kernel is to modify the \texttt{sys\_call\_table}. It is a data structure of function pointers, one for each possible syscall, used by the kernel to execute what the user has asked. The entire \texttt{sys\_call\_table} should not change over time, and that is why the kernel mark it as read only. However, attackers running code at Ring 0 can easily circumvent this policy. There are at least two ways to do that: walking the page tables and modifying the bit to allow write access or temporarily disable the CR0.WP bit. Both these two kind of attacks were unsuccessful:  the \texttt{sys\_call\_table} is placed in a PMC, thus modifying the page tables is useless, since writes to that part of memory are not allowed by the hypervisor. In addition, the CR0.WP bit is one of the pinned bits of CR0, and any attempt to modify it after its pinning is denied and logged. 

\par
These were the most relevant examples that needed to be discussed. Many other attacks could be implemented, but the point is that the memory protection and the save \& reload approach turned out to be effective against most of them, proving the robustness of the system. However, one of the most difficult attacks to deal with is the modification of the guest page tables. The previous discussion took into consideration the modification of the W bit in the page tables, but not what would happen if the translation was made pointing to another physical page. For instance, the translation of the symbol \texttt{sys\_call\_table} can be modified to point to a page containing a fake table, having some of the entries modified for malicious purposes. To detect this situation, the monitoring code can also check the integrity of the page tables and of the translation of relevant symbols using the Save \& Compare approach. Unfortunately, this allows to implement only a monitoring approach. To actually implement an active protection of the guest page tables, hardware support is needed, and Intel is beginning to work on it, as it will be discussed in Chapter \ref{chap:conclusions}.

\section{Hypercall performance}
Other relevant aspects to be evaluated are related to the performance of the system. One of the most important performance metrics to measure is the time needed to perform a hypercall, which is a crucial building block used by the monitoring code, allowing guest and host to communicate. To evaluate the time spent to perform a hypercall, three more of them were created just for this purpose. In particular, these are: 
\begin{itemize}
    \item Start timer hypercall: it is used by the FX device driver to start a timer inside the hypervisor.
    \item Empty hypercall: like its name suggests, it does nothing, since the objective here is to only measure how long it takes to exit the guest, returning to host userspace. 
    \item End timer hypercall: it is used by the FX device driver to stop the timer inside the hypervisor. 
\end{itemize}
\begin{figure}[t]
    \centering
    \includesvg[scale=0.9]{images/hypercall-plot.svg}
    \caption{Bar chart of hypercall time measurement experiments. The experiments were done with $n = 100000$ }
    \label{fig:perf-hypercall}
\end{figure}

The measurement must only take into account the time spent executing the empty hypercall, avoiding measuring the time for starting and stopping the timer. To solve this problem, a simple averaging strategy is used: the device driver starts the timer, then it performs \emph{n} empty hypercalls before stopping the timer. To compute the time spent for a single empty hypercall, the overall time measured by the timer is divided by the number of empty hypercalls performed. Of course, the error of this measurement decreases more and more as \emph{n} increases, until it can be considered negligible. The obtained results are shown in Figure \ref{fig:perf-hypercall}. The average time spent is 10.912 $\mu s$. 
